{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\Mohd Arshil/.cache\\torch\\hub\\ultralytics_yolov5_master\n",
      "YOLOv5  2025-1-26 Python-3.12.7 torch-2.5.1+cpu CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients, 16.4 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load(\"ultralytics/yolov5\", \"yolov5s\", pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"testImage.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[172, 168, 173],\n",
       "        [172, 168, 173],\n",
       "        [172, 168, 173],\n",
       "        ...,\n",
       "        [200, 203, 208],\n",
       "        [202, 205, 210],\n",
       "        [202, 205, 210]],\n",
       "\n",
       "       [[172, 168, 173],\n",
       "        [172, 168, 173],\n",
       "        [172, 168, 173],\n",
       "        ...,\n",
       "        [200, 203, 208],\n",
       "        [201, 204, 209],\n",
       "        [201, 204, 209]],\n",
       "\n",
       "       [[172, 168, 173],\n",
       "        [172, 168, 173],\n",
       "        [172, 168, 173],\n",
       "        ...,\n",
       "        [200, 203, 207],\n",
       "        [200, 203, 207],\n",
       "        [200, 203, 207]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[123, 123, 137],\n",
       "        [123, 123, 137],\n",
       "        [123, 123, 137],\n",
       "        ...,\n",
       "        [143, 137, 126],\n",
       "        [143, 137, 126],\n",
       "        [143, 137, 126]],\n",
       "\n",
       "       [[119, 118, 134],\n",
       "        [119, 118, 134],\n",
       "        [118, 117, 133],\n",
       "        ...,\n",
       "        [142, 138, 127],\n",
       "        [142, 138, 127],\n",
       "        [142, 138, 127]],\n",
       "\n",
       "       [[119, 118, 134],\n",
       "        [119, 118, 134],\n",
       "        [118, 117, 133],\n",
       "        ...,\n",
       "        [140, 136, 125],\n",
       "        [140, 136, 125],\n",
       "        [140, 136, 125]]], dtype=uint8)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Mohd Arshil/.cache\\torch\\hub\\ultralytics_yolov5_master\\models\\common.py:894: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with amp.autocast(autocast):\n"
     ]
    }
   ],
   "source": [
    "results = model(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "image 1/1: 720x1280 2 persons\n",
      "Speed: 8.5ms pre-process, 76.4ms inference, 14.5ms NMS per image at shape (1, 3, 384, 640)\n"
     ]
    }
   ],
   "source": [
    "results.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_objects = []\n",
    "for *xyxy, conf, cls in results.xyxy[0]:\n",
    "    # Get class name\n",
    "    class_name = model.names[int(cls)]\n",
    "    \n",
    "    # Convert coordinates to integers\n",
    "    x1, y1, x2, y2 = map(int, xyxy)\n",
    "    \n",
    "    # Create object info dictionary\n",
    "    obj_info = {\n",
    "        'class': class_name,\n",
    "        'confidence': float(conf),\n",
    "        'bbox': {\n",
    "            'x1': x1,\n",
    "            'y1': y1,\n",
    "            'x2': x2,\n",
    "            'y2': y2\n",
    "        }\n",
    "    }\n",
    "    detected_objects.append(obj_info)\n",
    "    \n",
    "    # Optional: Draw bounding box on image\n",
    "    cv2.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "    cv2.putText(img, f'{class_name} {conf:.2f}', (x1, y1-10), \n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
    "\n",
    "# Save output image\n",
    "cv2.imwrite('detected_objects.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class': 'person',\n",
       "  'confidence': 0.9400283098220825,\n",
       "  'bbox': {'x1': 386, 'y1': 190, 'x2': 1047, 'y2': 713}},\n",
       " {'class': 'person',\n",
       "  'confidence': 0.42326590418815613,\n",
       "  'bbox': {'x1': 938, 'y1': 1, 'x2': 1271, 'y2': 652}}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detected_objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML_Environment_1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
